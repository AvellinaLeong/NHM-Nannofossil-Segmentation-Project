{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcp1JwqVZkMf8rqIdV+2My",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AvellinaLeong/NHM-Nannofossil-Segmentation-Project/blob/main/04_evaluation_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Detectrons and Datasets"
      ],
      "metadata": {
        "id": "aKeyWL6Pv110"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G4cIwBZvgcP",
        "outputId": "28216bb6-1b69-41cc-b3e6-58d32a5bbbfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/MyDrive/development/avellina\n",
            "Binary_Classification_notebooks  Detectron2_notebooks  Mask-RCNN\t\toutput\n",
            "detectron2\t\t\t Extra_Data_Pipeline   Morphometrics_notebooks\tsrc\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# Set script location to own development space\n",
        "MY_DEVELOPMENT_SPACE = '/content/drive/MyDrive/development/avellina/'\n",
        "import os\n",
        "os.chdir(MY_DEVELOPMENT_SPACE)\n",
        "!pwd\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GCZfBv_6voAY",
        "outputId": "1cf26fba-7640-4dac-879e-91c21fa89928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/274.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/274.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.2/274.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "fatal: destination path 'detectron2' already exists and is not an empty directory.\n",
            "Ignoring dataclasses: markers 'python_version < \"3.7\"' don't match your environment\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (10.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (2.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (2.5.0)\n",
            "Collecting yacs>=0.1.8\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Collecting fvcore<0.1.6,>=0.1.5\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
            "Collecting omegaconf<2.4,>=2.1\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting hydra-core>=1.1\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting black\n",
            "  Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (24.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs>=0.1.8) (6.0.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.6)\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.4,>=2.1)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black) (4.3.6)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black) (2.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Building wheels for collected packages: fvcore, antlr4-python3-runtime\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=8502f4261abdff6b9c3588df636f66d7aa4a26fdb71d6c78293e2421f0855899\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=1f09be06ca1daf09b6fc9811d2bfe79b1e029d5728cbccd09adc13a90b7218b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built fvcore antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-24.10.0 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.12.1 portalocker-2.10.1 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_XAAJwYvpWZ",
        "outputId": "6b22de4e-3415-4ce2-f421-e19031fdd75c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "torch:  2.5 ; cuda:  cu121\n",
            "detectron2: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Detectron2 and logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRuRO-GHvrey",
        "outputId": "d3f8cb89-2662-4328-c3a1-a5e1abab336b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Logger detectron2 (DEBUG)>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import copy\n",
        "import numpy as np\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog, build_detection_test_loader, transforms as T\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.data import detection_utils as utils\n",
        "from detectron2.engine import DefaultTrainer\n",
        "import cv2\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode"
      ],
      "metadata": {
        "id": "kTmufTbZvs2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Register datasets\n",
        "register_coco_instances(\"my_dataset_val\", {}, \"/content/drive/MyDrive/data/species_53/data/val/coco_val.json\", \"/content/drive/MyDrive/data/species_53/data/val\")\n",
        "register_coco_instances(\"my_dataset_test\", {}, \"/content/drive/MyDrive/data/species_53/data/test/coco_test.json\", \"/content/drive/MyDrive/data/species_53/data/test\")"
      ],
      "metadata": {
        "id": "-u3bEMrRbHYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load metadata for visualization\n",
        "val_metadata = MetadataCatalog.get(\"my_dataset_val\")\n",
        "test_metadata = MetadataCatalog.get(\"my_dataset_test\")\n",
        "\n",
        "# Get val and test dataset dicts\n",
        "val_dataset_dicts = DatasetCatalog.get(\"my_dataset_val\")\n",
        "test_dataset_dicts = DatasetCatalog.get(\"my_dataset_test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq1utR6PvyWG",
        "outputId": "e34f543a-435f-496a-f230-e8a54701b519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11/04 14:54:40 d2.data.datasets.coco]: Loaded 95 images in COCO format from /content/drive/MyDrive/data/species_53/data/val/coco_val.json\n",
            "[11/04 14:54:41 d2.data.datasets.coco]: Loaded 96 images in COCO format from /content/drive/MyDrive/data/species_53/data/test/coco_test.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Augmentations and Load Configurations"
      ],
      "metadata": {
        "id": "Pz9rc7LMv43H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define augmentations\n",
        "from detectron2.data import transforms as T\n",
        "\n",
        "augs = T.AugmentationList([\n",
        "    T.RandomBrightness(0.9, 1.1),\n",
        "    T.RandomFlip(prob=0.5),\n",
        "    T.RandomRotation(angle=[-90, 90]),\n",
        "    T.RandomSaturation(0.8, 1.2),\n",
        "])"
      ],
      "metadata": {
        "id": "x4nKR81qv8v-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom data mapper\n",
        "def custom_mapper(dataset_dict):\n",
        "    dataset_dict = copy.deepcopy(dataset_dict)\n",
        "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
        "\n",
        "    # Get the annotations\n",
        "    annos = dataset_dict.get(\"annotations\", [])\n",
        "    bbox_list = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n",
        "    bbox_list = np.array(bbox_list, dtype=np.float32)\n",
        "\n",
        "    # Apply augmentations\n",
        "    aug_input = T.AugInput(image, boxes=bbox_list)\n",
        "    transforms = augs(aug_input)\n",
        "    image = aug_input.image\n",
        "\n",
        "    # Apply the same transforms to the annotations\n",
        "    annos = [utils.transform_instance_annotations(obj, transforms, image.shape[:2]) for obj in annos]\n",
        "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
        "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
        "    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
        "\n",
        "    return dataset_dict"
      ],
      "metadata": {
        "id": "9TAN8BhSv-D6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTrainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_train_loader(cls, cfg):\n",
        "        return build_detection_train_loader(cfg, mapper=custom_mapper)\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.OUTPUT_DIR = \"/content/drive/MyDrive/data/species_53/Detectron2_Models/5\" # Make sure this path is correct\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
        "cfg.DATASETS.VAL = (\"my_dataset_val\",)\n",
        "cfg.DATASETS.TEST = (\"my_dataset_test\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final_5.pth\")  # Make sure this path is correct\n",
        "cfg.MODEL.BACKBONE.FREEZE_AT = 0 # !!!!\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 1000\n",
        "cfg.SOLVER.STEPS = []\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
        "cfg.TEST.EVAL_PERIOD = 500\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "\n",
        "# Load the saved configuration from the YAML file\n",
        "config_yaml_path = \"/content/drive/MyDrive/data/species_53/Detectron2_Models/5/config_5.yaml\" # Make sure this path is correct\n",
        "cfg.merge_from_file(config_yaml_path)\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final_5.pth\") # Make sure this path is correct\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzjes759wHY-",
        "outputId": "2b85dcac-8588-4a0b-8a39-ddcb9825ad28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.config:Loading config /content/drive/MyDrive/data/species_53/Detectron2_Models/5/config_5.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the predictor\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bzBVngpwKFo",
        "outputId": "bca75c81-1b74-4bd4-f848-009a6cc7a581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11/04 14:55:00 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /content/drive/MyDrive/data/species_53/Detectron2_Models/5/model_final_5.pth ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location=torch.device(\"cpu\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run predictions on the val and test sets\n",
        "def get_predictions(dataset_dicts):\n",
        "    predictions = []\n",
        "    for data in dataset_dicts:\n",
        "        im = cv2.imread(data[\"file_name\"])\n",
        "        outputs = predictor(im)\n",
        "        predictions.append(outputs)\n",
        "    return predictions\n",
        "\n",
        "val_predictions = get_predictions(val_dataset_dicts)\n",
        "test_predictions = get_predictions(test_dataset_dicts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDBx8N7q2OeV",
        "outputId": "eb65e944-2b2d-4d47-a0d1-c7c8f3984d37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Precision, Recall and IOU"
      ],
      "metadata": {
        "id": "DkHBzJDmwMNm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the Ground Truth Data and Predictions"
      ],
      "metadata": {
        "id": "Dd0vSZyGyb9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import skimage.draw"
      ],
      "metadata": {
        "id": "yQEWJGr3x1kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_iou(b1, b2):\n",
        "    y1, x1, y2, x2 = max(b1[0], b2[0]), max(b1[1], b2[1]), min(b1[2], b2[2]), min(b1[3], b2[3])\n",
        "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "    b1_area = (b1[2] - b1[0]) * (b1[3] - b1[1])\n",
        "    b2_area = (b2[2] - b2[0]) * (b2[3] - b2[1])\n",
        "    union = b1_area + b2_area - intersection\n",
        "    return intersection / union if union != 0 else 0\n",
        "\n",
        "def get_TP_FP(pred_boxes, gt_boxes, iou_threshold=0.5):\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    matched_gt = []\n",
        "    for pred_box in pred_boxes:\n",
        "        match_found = False\n",
        "        for i, gt_box in enumerate(gt_boxes):\n",
        "            if i not in matched_gt:\n",
        "                iou = compute_iou(pred_box, gt_box)\n",
        "                if iou >= iou_threshold:\n",
        "                    tp += 1\n",
        "                    match_found = True\n",
        "                    matched_gt.append(i)\n",
        "                    break\n",
        "        if not match_found:\n",
        "            fp += 1\n",
        "    fn = len(gt_boxes) - tp\n",
        "    return tp, fp, fn\n",
        "\n",
        "def extract_bboxes(mask):\n",
        "    bboxes = []\n",
        "    for i in range(mask.shape[2]):\n",
        "        pos = np.where(mask[:, :, i])\n",
        "        xmin = np.min(pos[1])\n",
        "        xmax = np.max(pos[1])\n",
        "        ymin = np.min(pos[0])\n",
        "        ymax = np.max(pos[0])\n",
        "        bboxes.append([xmin, ymin, xmax, ymax])\n",
        "    return bboxes"
      ],
      "metadata": {
        "id": "j-qpbGQ32Ejd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_pred_masks_and_boxes(predictions):\n",
        "    pred_masks = []\n",
        "    pred_boxes = []\n",
        "    scores = []\n",
        "\n",
        "    for output in predictions:\n",
        "        instances = output[\"instances\"].to(\"cpu\")\n",
        "        pred_masks.append(instances.pred_masks.numpy())\n",
        "        pred_boxes.append(instances.pred_boxes.tensor.numpy())\n",
        "        scores.append(instances.scores.numpy())\n",
        "\n",
        "    return pred_masks, pred_boxes, scores"
      ],
      "metadata": {
        "id": "h9gP9SRo2GDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert predictions\n",
        "val_pred_masks, val_pred_boxes, val_scores = extract_pred_masks_and_boxes(val_predictions)\n",
        "test_pred_masks, test_pred_boxes, test_scores = extract_pred_masks_and_boxes(test_predictions)"
      ],
      "metadata": {
        "id": "tr4KCvp5GL_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_info(annotations, height, width):\n",
        "    info = {\"height\": height, \"width\": width, \"polygons\": [a[\"segmentation\"] for a in annotations if \"segmentation\" in a and a[\"segmentation\"]]}\n",
        "    return info\n",
        "\n",
        "def ground_truth_masks(data, height, width):\n",
        "    info = create_info(data[\"annotations\"], height, width)\n",
        "    mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])], dtype=np.uint8)\n",
        "    for i, p in enumerate(info[\"polygons\"]):\n",
        "        if not p or len(p[0]) < 3:  # Check if the polygon list is empty or invalid\n",
        "            print(f\"Invalid or empty polygon for annotation {i} in file {data['file_name']}\")\n",
        "            continue\n",
        "        rr, cc = skimage.draw.polygon(p[0][1::2], p[0][0::2])\n",
        "        mask[rr, cc, i] = 1\n",
        "    return mask"
      ],
      "metadata": {
        "id": "8VSrcWy82jV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ground truth masks for the val and test sets\n",
        "ground_truth_masks_dict = {}\n",
        "for data in val_dataset_dicts:\n",
        "    filename = data[\"file_name\"]\n",
        "    height, width = data[\"height\"], data[\"width\"]\n",
        "    mask = ground_truth_masks(data, height, width)\n",
        "    ground_truth_masks_dict[filename] = mask\n",
        "\n",
        "ground_truth_masks_dict_test = {}\n",
        "for data in test_dataset_dicts:\n",
        "    filename = data[\"file_name\"]\n",
        "    height, width = data[\"height\"], data[\"width\"]\n",
        "    mask = ground_truth_masks(data, height, width)\n",
        "    ground_truth_masks_dict_test[filename] = mask\n",
        "\n",
        "print(\"Ground truth masks for validation set created successfully\")\n",
        "print(\"Ground truth masks for test set created successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8sh53r82lvi",
        "outputId": "647ad7b4-2c59-4c0b-c775-1f970361aa0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground truth masks for validation set created successfully\n",
            "Ground truth masks for test set created successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Precision, Recall and IOU Calculate on Val and Test Sets\n"
      ],
      "metadata": {
        "id": "wixuTQNlyp6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import auc"
      ],
      "metadata": {
        "id": "xr6rYEhWyuE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predicted masks for validation and test sets\n",
        "val_pred_masks, _, _ = extract_pred_masks_and_boxes(val_predictions)\n",
        "test_pred_masks, _, _ = extract_pred_masks_and_boxes(test_predictions)"
      ],
      "metadata": {
        "id": "G1ePTAHUEG0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dictionaries to hold predicted masks\n",
        "val_pred_masks_dict = {}\n",
        "for i, data in enumerate(val_dataset_dicts):\n",
        "    filename = data[\"file_name\"]\n",
        "    val_pred_masks_dict[filename] = val_pred_masks[i]\n",
        "\n",
        "test_pred_masks_dict = {}\n",
        "for i, data in enumerate(test_dataset_dicts):\n",
        "    filename = data[\"file_name\"]\n",
        "    test_pred_masks_dict[filename] = test_pred_masks[i]"
      ],
      "metadata": {
        "id": "UYfPTTFmEKHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(dataset_dicts, pred_boxes, ground_truth_masks_dict):\n",
        "    all_tp, all_fp, all_fn = 0, 0, 0\n",
        "    ious = []\n",
        "\n",
        "    for data, pred_box in zip(dataset_dicts, pred_boxes):\n",
        "        filename = data[\"file_name\"]\n",
        "        gt_mask = ground_truth_masks_dict[filename]\n",
        "        gt_boxes = extract_bboxes(gt_mask)\n",
        "        tp, fp, fn = get_TP_FP(pred_box, gt_boxes)\n",
        "        all_tp += tp\n",
        "        all_fp += fp\n",
        "        all_fn += fn\n",
        "        for pred_b, gt_b in zip(pred_box, gt_boxes):\n",
        "            ious.append(compute_iou(pred_b, gt_b))\n",
        "\n",
        "    precision = all_tp / (all_tp + all_fp) if (all_tp + all_fp) > 0 else 0\n",
        "    recall = all_tp / (all_tp + all_fn) if (all_tp + all_fn) > 0 else 0\n",
        "    mean_iou = np.mean(ious) if ious else 0\n",
        "    accuracy = all_tp / (all_tp + all_fp + all_fn) if (all_tp + all_fp + all_fn) > 0 else 0\n",
        "\n",
        "    return precision, recall, mean_iou, accuracy\n",
        "\n",
        "# Compute metrics for validation set\n",
        "val_precision, val_recall, val_mean_iou, val_accuracy = compute_metrics(val_dataset_dicts, val_pred_boxes, ground_truth_masks_dict)\n",
        "print(\"Validation - Precision:\", val_precision)\n",
        "print(\"Validation - Recall:\", val_recall)\n",
        "print(\"Validation - Mean IoU:\", val_mean_iou)\n",
        "print(\"Validation - Accuracy:\", val_accuracy)\n",
        "\n",
        "# Compute metrics for test set\n",
        "test_precision, test_recall, test_mean_iou, test_accuracy = compute_metrics(test_dataset_dicts, test_pred_boxes, ground_truth_masks_dict_test)\n",
        "print(\"Test - Precision:\", test_precision)\n",
        "print(\"Test - Recall:\", test_recall)\n",
        "print(\"Test - Mean IoU:\", test_mean_iou)\n",
        "print(\"Test - Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dvdQU_r-7uJn",
        "outputId": "59de6b33-317e-4b64-f583-e97407194b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Precision: 0.7983870967741935\n",
            "Validation - Recall: 0.9611650485436893\n",
            "Validation - Mean IoU: 0.7885116001897382\n",
            "Validation - Accuracy: 0.7734375\n",
            "Test - Precision: 0.7835820895522388\n",
            "Test - Recall: 0.9722222222222222\n",
            "Test - Mean IoU: 0.8005595759821296\n",
            "Test - Accuracy: 0.7664233576642335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------- Model (train resnet layers) ---------------\n",
        "# Validation - Precision: 0.7983870967741935\n",
        "# Validation - Recall: 0.9611650485436893\n",
        "# Validation - Mean IoU: 0.7885116001897382\n",
        "# Validation - Accuracy: 0.7734375\n",
        "# Test - Precision: 0.7835820895522388\n",
        "# Test - Recall: 0.9722222222222222\n",
        "# Test - Mean IoU: 0.8005595759821296\n",
        "# Test - Accuracy: 0.7664233576642335"
      ],
      "metadata": {
        "id": "L4rbB5b9doQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model without normalisation\n",
        "# Validation - Precision: 0.8135593220338984\n",
        "# Validation - Recall: 0.46601941747572817\n",
        "# Validation - Mean IoU: 0.5399237047686556\n",
        "# Validation - Accuracy: 0.42105263157894735\n",
        "# Test - Precision: 0.7017543859649122\n",
        "# Test - Recall: 0.37037037037037035\n",
        "# Test - Mean IoU: 0.47500537918242575\n",
        "# Test - Accuracy: 0.32"
      ],
      "metadata": {
        "id": "--8q1h4B70mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with normalisation cv2\n",
        "# Validation - Precision: 0.6578947368421053\n",
        "# Validation - Recall: 0.7281553398058253\n",
        "# Validation - Mean IoU: 0.5794849551875569\n",
        "# Validation - Accuracy: 0.528169014084507\n",
        "# Test - Precision: 0.572463768115942\n",
        "# Test - Recall: 0.7314814814814815\n",
        "# Test - Mean IoU: 0.4447712056723371\n",
        "# Test - Accuracy: 0.47305389221556887"
      ],
      "metadata": {
        "id": "Nm5aoml6dDty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with per channel standardisation\n",
        "# Validation - Precision: 0.5189873417721519\n",
        "# Validation - Recall: 0.39805825242718446\n",
        "# Validation - Mean IoU: 0.4441316441016047\n",
        "# Validation - Accuracy: 0.2907801418439716\n",
        "# Test - Precision: 0.4578313253012048\n",
        "# Test - Recall: 0.35185185185185186\n",
        "# Test - Mean IoU: 0.3856891764891272\n",
        "# Test - Accuracy: 0.24836601307189543"
      ],
      "metadata": {
        "id": "J-2hSJpK6EM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boundary F1 Score on Val and Test Sets"
      ],
      "metadata": {
        "id": "4fBozT_a-4Vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import skimage\n",
        "from skimage.segmentation import find_boundaries"
      ],
      "metadata": {
        "id": "tyfniURt-8Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This isn't working -- invalid prediction format"
      ],
      "metadata": {
        "id": "AAAScke1K2m2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import skimage.draw\n",
        "from skimage.segmentation import find_boundaries\n",
        "\n",
        "# Function to compute boundary F1 score\n",
        "def compute_boundary_f1_score(dataset_dicts, predictions, ground_truth_masks_dict):\n",
        "    precisions, recalls, f1_scores = [], [], []\n",
        "\n",
        "    for data, pred_masks_list in zip(dataset_dicts, predictions):\n",
        "        filename = data[\"file_name\"]\n",
        "\n",
        "        # Ensure pred_masks is accessed correctly based on the actual structure of predictions\n",
        "        if isinstance(pred_masks_list, list) and pred_masks_list:\n",
        "            pred_masks = pred_masks_list[0][\"instances\"].pred_masks.numpy()  # Assuming first prediction instance\n",
        "        else:\n",
        "            print(f\"Invalid prediction format for {filename}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        gt_mask = ground_truth_masks_dict[filename]\n",
        "\n",
        "        pred_boundaries = find_boundaries(pred_masks)\n",
        "        gt_boundaries = find_boundaries(gt_mask)\n",
        "\n",
        "        # Flatten masks to compute TP, FP, FN\n",
        "        pred_boundaries_flat = pred_boundaries.flatten()\n",
        "        gt_boundaries_flat = gt_boundaries.flatten()\n",
        "\n",
        "        # Compute TP, FP, FN\n",
        "        TP = np.sum(np.logical_and(pred_boundaries_flat, gt_boundaries_flat))\n",
        "        FP = np.sum(np.logical_and(pred_boundaries_flat, np.logical_not(gt_boundaries_flat)))\n",
        "        FN = np.sum(np.logical_and(np.logical_not(pred_boundaries_flat), gt_boundaries_flat))\n",
        "\n",
        "        # Compute precision, recall, f1 score\n",
        "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    avg_precision = np.mean(precisions)\n",
        "    avg_recall = np.mean(recalls)\n",
        "    avg_f1_score = np.mean(f1_scores)\n",
        "\n",
        "    return avg_precision, avg_recall, avg_f1_score\n",
        "\n",
        "# Assuming val_dataset_dicts, test_dataset_dicts, val_predictions, test_predictions, ground_truth_masks_dict, ground_truth_masks_dict_test are defined\n",
        "\n",
        "# Compute boundary F1 score for validation set\n",
        "val_avg_precision, val_avg_recall, val_avg_f1_score = compute_boundary_f1_score(val_dataset_dicts, val_predictions, ground_truth_masks_dict)\n",
        "print(\"Validation - Average Precision:\", val_avg_precision)\n",
        "print(\"Validation - Average Recall:\", val_avg_recall)\n",
        "print(\"Validation - Average Boundary F1 Score:\", val_avg_f1_score)\n",
        "\n",
        "# Compute boundary F1 score for test set\n",
        "test_avg_precision, test_avg_recall, test_avg_f1_score = compute_boundary_f1_score(test_dataset_dicts, test_predictions, ground_truth_masks_dict_test)\n",
        "print(\"Test - Average Precision:\", test_avg_precision)\n",
        "print(\"Test - Average Recall:\", test_avg_recall)\n",
        "print(\"Test - Average Boundary F1 Score:\", test_avg_f1_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7luuR3BfIvT6",
        "outputId": "16a8677c-68c9-41e0-a91c-bb731a15ab62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5054_01_29.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5054_03_40.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5065_06_1.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5065_06_42.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5065_08_21.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5065_09_3.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5065_12_8.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5065_12_14.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5065_13_32.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5065_13_47.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5065_18_37.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5065_20_29.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5065_20_35.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5065_25_41.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5065_26_25.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5065_26_33.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5065_29_38.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5065_30_33.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5290_19_16.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5290_25_8.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5290_26_46.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5291_11_31.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5295_03_5.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5306_100_45.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5309_01_47.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5309_02_16.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5309_03_7.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5309_19_40.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5310_11_27.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5311_01_9.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5311_03_38.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5311_11_38.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5311_33_20.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5311_34_1.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5311_47_23.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5311_82_45.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5311_105_11.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_01_11.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_02_26.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_13_43.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_13_44.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_15_15.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_16_7.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_16_9.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_19_1.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_21_7.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_23_12.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_34_2.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_37_6.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_38_4.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_45_41.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_49_3.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_49_30.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_50_19.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_50_40.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_52_4.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_55_1.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_57_12.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_57_28.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_61_13.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5341_10_38.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5362_01_29.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5362_01_31.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5362_05_21.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5362_09_13.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5362_12_2.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5362_13_15.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5362_13_45.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5362_16_25.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5362_16_44.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5362_18_25.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5362_18_36.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5362_19_44.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5362_21_33.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5362_28_30.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5362_30_29.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5362_32_18.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5362_32_38.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5362_33_20.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5362_33_39.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5362_34_6.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5384_16_11.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5404_01_40.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5408_04_1.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5408_13_10.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5408_13_38.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5408_17_43.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5408_35_39.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5408_36_35.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5408_39_38.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5408_42_9.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5408_43_20.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5408_46_7.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5429_05_23.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/val/PM_NF_5338_20_20.jpeg. Skipping...\n",
            "Validation - Average Precision: nan\n",
            "Validation - Average Recall: nan\n",
            "Validation - Average Boundary F1 Score: nan\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_4980_02_13.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_4980_03_33.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5006_02_2.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5027_01_20.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5065_02_27.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5065_03_14.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5065_11_40.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5065_15_36.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5065_15_37.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5065_18_44.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5065_19_41.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5065_20_6.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5065_21_43.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5065_21_45.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5065_25_30.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5065_28_13.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5065_30_22.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5281_02_28.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5283_04_19.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5290_25_13.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5290_27_9.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5290_28_12.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5290_31_15.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5290_37_32.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5293_01_29.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5294_03_21.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5295_02_45.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5301_06_11.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5306_05_47.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5306_08_18.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5306_34_23.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5306_97_23.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5306_101_34.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5306_121_41.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5306_123_46.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5309_03_20.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5309_05_18.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5309_07_24.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5310_03_26.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5310_12_8.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5311_15_12.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5311_16_12.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5311_34_38.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5311_36_38.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5311_44_33.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5311_53_21.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5311_70_45.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5311_73_7.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5311_89_28.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5311_99_29.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5311_102_38.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5338_02_12.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5338_02_32.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5338_03_24.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5338_03_45.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5338_04_9.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5338_05_2.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5338_05_27.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5338_09_38.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5338_10_34.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5338_12_6.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5338_16_28.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5338_22_47.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5338_24_41.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5338_27_13.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5338_33_9.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5338_33_20.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5338_50_4.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5338_50_22.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5338_53_47.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5338_54_16.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5362_06_37.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5362_07_20.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5362_07_41.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5362_10_1.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5362_11_23.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5362_13_28.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5362_13_40.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5362_14_35.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5362_19_2.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5362_24_11.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5362_28_27.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5362_29_9.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5362_29_33.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5362_32_20.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5362_33_26.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5362_34_33.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5377_06_14.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5379_06_37.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5384_51_10.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5408_11_2.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5408_17_4.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5408_25_4.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5423_07_11.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5429_63_40.jpeg. Skipping...\n",
            "Invalid prediction format for /content/drive/MyDrive/data/species_53/data/test/PM_NF_5498_01_20.jpeg. Skipping...\n",
            "Test - Average Precision: nan\n",
            "Test - Average Recall: nan\n",
            "Test - Average Boundary F1 Score: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    }
  ]
}