{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6iU7RVQmT9LpeEnUgGeRp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AvellinaLeong/NHM-Nannofossil-Segmentation-Project/blob/main/01_JSONCOCO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert JSON Annotation to COCO JSON Format\n",
        "\n",
        "Output: COCO JSON annotated images saved to correct directories"
      ],
      "metadata": {
        "id": "GhvHiCQkWqUR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGVOEzTPWVYZ",
        "outputId": "c8294fa1-425a-4338-deb7-111bce2e701b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/MyDrive/development/avellina\n",
            "detectron2  Detectron2\tMask-RCNN\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# Set script location to own development space\n",
        "MY_DEVELOPMENT_SPACE = '/content/drive/MyDrive/development/avellina/'\n",
        "import os\n",
        "os.chdir(MY_DEVELOPMENT_SPACE)\n",
        "!pwd\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "project_dir = \"/content/drive/MyDrive/data/species_53\""
      ],
      "metadata": {
        "id": "XVrcIesTZNxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert JSON to COCO JSON"
      ],
      "metadata": {
        "id": "ji8G0HupZala"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "x6Y3cjUBZP77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_coco(json_file, output_file, category_id=1):\n",
        "    with open(json_file) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    coco_format = {\n",
        "        \"images\": [],\n",
        "        \"annotations\": [],\n",
        "        \"categories\": [{\n",
        "            \"id\": category_id,\n",
        "            \"name\": \"t_orionatus\",   # change to specific nannofossil species\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    annotation_id = 1\n",
        "    for idx, (file_key, info) in enumerate(data.items()):\n",
        "        image_id = idx + 1\n",
        "        filename = info[\"filename\"]\n",
        "        full_path = os.path.join(os.path.dirname(json_file), filename)\n",
        "\n",
        "        # Read the image to get dimensions\n",
        "        image = cv2.imread(full_path)\n",
        "        if image is None:\n",
        "            print(f\"Error reading image {full_path}\")\n",
        "            continue\n",
        "        height, width = image.shape[:2]\n",
        "\n",
        "        coco_format[\"images\"].append({\n",
        "            \"id\": image_id,\n",
        "            \"file_name\": filename,\n",
        "            \"height\": height,\n",
        "            \"width\": width,\n",
        "        })\n",
        "\n",
        "        for region in info[\"regions\"]:\n",
        "            shape_attributes = region.get(\"shape_attributes\", {})\n",
        "            all_points_x = shape_attributes.get(\"all_points_x\", [])\n",
        "            all_points_y = shape_attributes.get(\"all_points_y\", [])\n",
        "\n",
        "            if not all_points_x or not all_points_y:\n",
        "                print(f\"No points found for region in {filename}\")\n",
        "                continue\n",
        "\n",
        "            # Calculate bounding boxes\n",
        "            x_min = min(all_points_x)\n",
        "            y_min = min(all_points_y)\n",
        "            x_max = max(all_points_x)\n",
        "            y_max = max(all_points_y)\n",
        "            width = x_max - x_min\n",
        "            height = y_max - y_min\n",
        "            bbox = [x_min, y_min, width, height]\n",
        "\n",
        "            # Create segmentations\n",
        "            segmentation = []\n",
        "            for x, y in zip(all_points_x, all_points_y):\n",
        "                segmentation.append([x, y])\n",
        "            segmentation = [point for sublist in segmentation for point in sublist]\n",
        "\n",
        "            annotation = {\n",
        "                \"id\": annotation_id,\n",
        "                \"image_id\": image_id,\n",
        "                \"category_id\": category_id,\n",
        "                \"bbox\": bbox,\n",
        "                \"bbox_mode\": 1,\n",
        "                \"area\": width * height,\n",
        "                \"segmentation\": [segmentation],\n",
        "                \"iscrowd\": 0,\n",
        "            }\n",
        "            coco_format[\"annotations\"].append(annotation)\n",
        "            annotation_id += 1\n",
        "\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(coco_format, f, indent=4)\n",
        "    print(f\"Saved COCO format JSON to {output_file}\")\n",
        "\n",
        "# Convert train, val, and test JSON files to COCO JSON format\n",
        "sub_dirs = [\"train\", \"val\", \"test\"]\n",
        "file_names = [\"t_orionatus_label_train_json.json\", \"t_orionatus_label_val_json.json\", \"t_orionatus_label_test_json.json\"]\n",
        "output_names = [\"coco_train.json\", \"coco_val.json\", \"coco_test.json\"]\n",
        "\n",
        "for sub_dir, file_name, output_name in zip(sub_dirs, file_names, output_names):\n",
        "    json_file = os.path.join(project_dir, \"data\", sub_dir, file_name)\n",
        "    output_file = os.path.join(project_dir, \"data\", sub_dir, output_name)\n",
        "    convert_to_coco(json_file, output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl0PQn4ieVpx",
        "outputId": "f96d3157-d631-4734-cbf8-812aaac334cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved COCO format JSON to /content/drive/MyDrive/data/species_53/data/train/coco_train.json\n",
            "Saved COCO format JSON to /content/drive/MyDrive/data/species_53/data/val/coco_val.json\n",
            "Saved COCO format JSON to /content/drive/MyDrive/data/species_53/data/test/coco_test.json\n"
          ]
        }
      ]
    }
  ]
}
